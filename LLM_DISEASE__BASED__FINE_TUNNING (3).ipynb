{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbw1Le5W0m6d"
   },
   "source": [
    "Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AmVD-__ALgZj",
    "outputId": "2ce60fdf-1c32-4d50-bc36-6b75013022ca"
   },
   "outputs": [],
   "source": [
    "!pip install -q kaggle\n",
    "!pip install -q transformers accelerate bitsandbytes peft trl datasets scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b38xipTw0snk"
   },
   "source": [
    "Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z_CtJQvHUiOq",
    "outputId": "4a9220d0-3de4-4fa0-ac43-f48c9523e6c2"
   },
   "outputs": [],
   "source": [
    "import os,zipfile,json\n",
    "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
    "!mv \"kaggle (9).json\" /root/.kaggle/\n",
    "os.chmod(\"/root/.kaggle/kaggle (9).json\", 0o600)\n",
    "print(\"Kaggle API set successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZP_dHtiD0xk7"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "exu_h5Tpl-ZW",
    "outputId": "b019e19b-8a32-4046-eed7-047c70ae6ead"
   },
   "outputs": [],
   "source": [
    "zip_path=\"/content/archive (19).zip\"\n",
    "extract_path=\"/content/data\"\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "print(\"extracted files :\",os.listdir(extract_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOhmzckbfs1b"
   },
   "source": [
    "JSONL CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Aam_t7iDsiy6",
    "outputId": "751c7b83-e890-41de-8e67-69c9bb946606"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import os\n",
    "csv_path = \"/content/data/DiseaseAndSymptoms.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "symptom_cols = [c for c in df.columns if c.lower().startswith(\"symptom\")]\n",
    "print(\"Symptom columns:\", symptom_cols[:10], \"...\")\n",
    "def row_to_example(row):\n",
    "    symptoms = [str(s).strip() for s in row[symptom_cols] if pd.notnull(s)]\n",
    "    symptom_str = \", \".join(symptoms)\n",
    "\n",
    "    disease = str(row[\"Disease\"]).strip()\n",
    "\n",
    "    example = {\n",
    "        \"instruction\": \"Identify the most likely disease pattern from the dataset based on these symptoms.\",\n",
    "        \"input\": symptom_str,\n",
    "        \"output\": (\n",
    "            f\"Disease: {disease}\\n\"\n",
    "            f\"Explanation: These symptoms frequently appear together for {disease} \"\n",
    "            f\"in the training dataset examples.\\n\"\n",
    "            \"Note: This is NOT medical or diagnostic advice. \"\n",
    "            \"For any real health concerns, please consult a licensed doctor or emergency services.\"\n",
    "        ),\n",
    "\n",
    "        \"label\": disease\n",
    "    }\n",
    "    return example\n",
    "\n",
    "examples = [row_to_example(r) for _, r in df.iterrows()]\n",
    "print(\"Total examples:\", len(examples))\n",
    "\n",
    "train_data, test_data = train_test_split(examples, test_size=0.2, random_state=42, stratify=[e[\"label\"] for e in examples])\n",
    "\n",
    "os.makedirs(\"data_llm\", exist_ok=True)\n",
    "\n",
    "def write_jsonl(path, data):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for ex in data:\n",
    "            f.write(json.dumps(ex, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "write_jsonl(\"data_llm/train.jsonl\", train_data)\n",
    "write_jsonl(\"data_llm/test.jsonl\", test_data)\n",
    "\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDYKweia1LEc"
   },
   "source": [
    "LLM fine tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284,
     "referenced_widgets": [
      "d7290ed55aef480d8dc74fa1613a6709",
      "2ff468e0a7804321b80589132ea793a1",
      "69cfc5d514324d1ba619bb2b1a05700a",
      "78d346426e714e19b44acf9afd8a438d",
      "4f414fa6ae104209a8d91e5c3d2f4ec3",
      "9e50e3f535a64435ba2184700daa2160",
      "af846c8e73d148b29dc943d2a01a8bf5",
      "2a1b0ecafc834e7896f063babb01ba75",
      "9681852863674702be206cd4d8226beb",
      "8064b95aa1234039acf25d22ba8ee77b",
      "538f5d1ff6c14e2b89a8c65ca5f870dc",
      "caf65bcb85e945b7a7f207afa3efb920",
      "f8fbfa78780a4aeba607ccd49206cdad",
      "5de550e1f97d44b8bd92a68e9b9933e4",
      "41e00d8c919346d0aba7f1705bcb0fe8",
      "5efdff5b88a545d18ae2ad06d889a5a0",
      "f1c1d4fc5ea846aea3927dfb797577ad",
      "466e7746bc8c4a418c41fb252e4a9a14",
      "37918d74da2a4cabb8dc600496df98e5",
      "5b6893967d39459ea1cb3882ebba0100",
      "61777aaae94e4c65b73947074396d887",
      "10563cd1484e44558f61db4c0208cec7",
      "e8d010bb3ba846b19360130e74a0d722",
      "262b0312460e4e31a5d93d07c25404de",
      "9a111ca590d8400e98ccc5fc01e472ea",
      "a367e81c05574450be01e8700b1b5469",
      "7a87c165b2c14d0cb0d7662ecabf8109",
      "743a8f6960684220af485ce0cff32122",
      "23a8477fed4d49a485bfb1253194cb29",
      "cf6d702382a24d57b1f3aae80ae041d0",
      "29552f50b750478d99acb0f0c4fe499b",
      "ee6847a1ff65478188369f7b24c3c533",
      "bd7280f9b15f4940afc077cffc4ffcec",
      "bdf16e56448d4866b0e2baf46320bacf",
      "e436298c86464aec94ca2aaea825d1aa",
      "b6cf9ae935bb44d4b1e40880ad811071",
      "afc49d0f56904d7891a6b4669aee6021",
      "91249f1469074a44a84e88f865b21b78",
      "87c752de0bf3474284c35b97a8737b4c",
      "a904949f27254cc89d958bda8cdb2450",
      "b9fc03536d8c4fc9a122140cd09b21d6",
      "978b55eb85a34a45b6cbb7adf137b6c8",
      "f02d6826a87a403bb6dde4ccd7936027",
      "132d7947942f44ce896647231b78f549"
     ]
    },
    "id": "KikXQR_2vOxb",
    "outputId": "ea339622-39d5-47d2-cd27-dc1468e7a28c"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "data_files={\"train\":\"data_llm/train.jsonl\",\"test\":\"data_llm/test.jsonl\"}\n",
    "raw_datasets=load_dataset(\"json\",data_files=data_files,split={\"train\": \"train\", \"test\":\"test\"})\n",
    "def format_example(example):\n",
    "    return{\n",
    "        \"text\": (\n",
    "            f\"Instruction: {example['instruction']}\\n\"\n",
    "            f\"Symptoms: {example['input']}\\n\\n\"\n",
    "            f\"Response:\\n{example['output']}\"\n",
    "        )\n",
    "    }\n",
    "datset=raw_datasets[\"train\"].map(format_example)\n",
    "datset_test=raw_datasets[\"test\"].map(format_example)\n",
    "datset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365,
     "referenced_widgets": [
      "9a96171d57a04d23a5aa86629bf74287",
      "5c8fb8947cf74f6896b02ebe6ad252a1",
      "61a4758a22d54743a66e6d7b7587ff53",
      "bcaf19c340574516b312103ac2c5b9f4",
      "cad0e1ef69fc41dc993870e8d6459212",
      "d858d6411ffe4b44a5efcaf1a1e3fa7f",
      "f8725004d81e414ea4ce4924d6f8f35d",
      "b0de2ec4561c4fd587dc690c641f64ac",
      "c1540f1dd41340a696599b4e96f3e598",
      "4bc50d6871844c30b2bdffd24ae64f80",
      "3e503610ec784b909c55f0f41d38c1af",
      "fbae53ef928d425a888fbfb78fce4dad",
      "0e6023fcfcd64015bfd206be4c107bc0",
      "1d9b9cf8d5d640edabe5e38b56fe9d13",
      "0fccbeea931b4332afe5651468cba91d",
      "baac49f2053b43e9ae44b79c49943006",
      "2c33b535d6d5464baae06a8dcff1fb7d",
      "3e7115877ed94914978de3008a84e32f",
      "b8e7dfbd28ca4fa2be20e63fdda55c5e",
      "7fc714c717234926b96e506c0c5471dd",
      "f422ed3c69024d778d61cbfeffb076a1",
      "7003c9783fc34b22a40234ef1342462d",
      "2620490ee37549a7b59049c09770b3d6",
      "07b90b0536c94a6ba76db79ec93a229d",
      "2946686b016c4846ba6b2d1136709834",
      "a6972f58ed144b20bca52428a3d0f0ef",
      "60e926e6e2494991b2bc3dd0cef633bd",
      "645b702f590943fe8e8061a2d8ab118f",
      "c9fb89fc00eb49218fad432b6cd570bb",
      "7949591d1c784293b1203f3fd4dba099",
      "adf851b69d2946c2af880e8e9b27d556",
      "03bb307a0fb24073bb62aaead1f02554",
      "91b0ae1e08fb47efb9f4e00f9c732b25",
      "286244f38d1343e691193ad51205ff2a",
      "e0e35f2bd2cb45dc9f016baa0b218149",
      "67c5d4f600824a57af7bd93a54998abd",
      "8c1988c2a35744dcaf7b457b1194ca07",
      "eb1acccdfbc942b4ac126c7b979d66e9",
      "d8c7bce734424ee1ab2dc3539d4136d8",
      "3cd00bd71a994caba03f3bcf8ced2268",
      "88db930d5038442d8421d1640be6d99d",
      "189667adf17f4fcda669bdedb8b255a0",
      "2d43b37578d84bfb80402c31f11ef21c",
      "6672683e2746409790b5b71d6ee76117",
      "a20c9aade803455db43adf84c2048550",
      "b34e3947542a4982a59ece5c4559b94d",
      "d446cd66cc864024a46961c5a3257af5",
      "85b165edb0ff4159bad114f1c977215a",
      "439075a8e8cd4456a75e5c0226a3730c",
      "6243344318a643c8ae95dc0a45d8ebaf",
      "f8bfdbc1af5a4762a69a9afaf796eb3d",
      "cc1d618f7c9c478880f752fd2bfdbdff",
      "af907380dd4743c5b8292571658fdecc",
      "e94a81d9a87e4018887739bc1d86a939",
      "efe3c387b3e54affb54fe9e1e27523a8",
      "d2f2bec4713646d193d52afe4625ceb8",
      "d726100445214e88b4bcc897df2687c7",
      "f4f6846a321a4cd0aa042bdc4bd8bf81",
      "5d7d7b2d086948fe929a74fefe533330",
      "37926a1933bd42419230fdc191af3446",
      "6fb72f8ad56f42da99f787e48dd280e5",
      "f89e92255e19451b8d9cf925169d28d8",
      "acbad93dbfd64a49a7a7091ed0dd62db",
      "ce854f11fefa4d319cab0c9bf0ffe5eb",
      "b11c89c894a7492bb2e866ba1d44062e",
      "693bb03859cf41578073831aeb10242c",
      "dda6d457e90e4d56a0df0fac56d752c4",
      "599b5ec4bd6a4c34bbdf4a4494808185",
      "3265017b05f9444bb323d0d544b048be",
      "4680b9a013ed447b871805dbf319b4d6",
      "3cb46b2611f247648c06ccafbf4d267c",
      "4cff0c5d0df143b18161b6a0f2ccc643",
      "aa43e981cfa64fcaa7b197096efc9a3b",
      "83b81570e5684a9dbd52fbdbb53756e1",
      "12ccad4f110641e49e3d41a433b321cd",
      "b58b2cac47894333882623413f2926f7",
      "64c201053f2347a7a8e298ec9d2521b6"
     ]
    },
    "id": "_T67CtE4pK-y",
    "outputId": "6e9c2868-1407-4291-e628-12dbab88d5b1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "base_model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "# 4-bit quantization (QLoRA)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, use_fast=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371,
     "referenced_widgets": [
      "83474ec98f3c4cbb8e0dff9f76ccf85e",
      "08037b3880944e6a99c356d2017fedef",
      "fd50495071c946f284231a0064f935f4",
      "39089ec306644b7bbc029e0a9d3798d1",
      "1f607d7f2792451bb67f558a4e1e0add",
      "f64fa4ea325f4c64951d46bdd7555631",
      "813f41f17ee04a9e8b1a59a4343e63d7",
      "389c0b290a45470c854a3b3c5a925e18",
      "fd931d2a63ee4d679200093fb2df9951",
      "b79f026b8799437ebb72bfbe4b13b1af",
      "aa9f2aeed8d2487ba3a5d551a935e0af",
      "d050637054a94c66a11fd41b5269a187",
      "ac3b86def4bc4a8b8b64308bb2f498ab",
      "cc44f80241ae4bc9a008a0e814e38a1b",
      "fdb82c86230e4b2f90dc7b9b0c317021",
      "2e833cdf47194fdea7550d9c6dd92970",
      "98b8010c72b440e79614df886b7ad599",
      "1d597f08730a4125aeaa985d64857a33",
      "476550d366b84737ba47e03acb8bb3ff",
      "ae52c5d2533545f39c86e3087378726f",
      "844b760bedc941a6a1608f3fbb170422",
      "e174f0f50dfe469ba501bba99d10cf6d",
      "5d4560451cc346ada5312076fdb950fc",
      "7b0a438362bb42cd8415ffa682a7a582",
      "09186684f7804bb2905598676800bc25",
      "bb1245b4ec264c97a51dbd683748381b",
      "baee3feae6b945528017de7094691547",
      "acaf44db7b5648aa93bba20344f72979",
      "d706239c8c674f618dc686afaed759ef",
      "f4357913f74b445683f0c0c8c3ec8986",
      "5cdbd93da2dd47dc9d822c47e6256c4d",
      "0e370a844ceb4d398e4e1ffe75a6e67b",
      "f39ed2b381344bbd936d92742bb56eba",
      "e8fb05ac9eb94aa39736a0f0884546bd",
      "f92bee921b054ed286c194af74d17714",
      "d64647a1e8a04c4288392f10284f1f92",
      "bd6cb40ca7a740edbe33f5c04e0f6f24",
      "f22f754a8537465a97b926931710d38b",
      "460efc25f13b4f3cb908aa62de0f578f",
      "811e6b10305043279bf89389ee3d3fa5",
      "ce92fed4f251427396eabfcd6cbb5e6b",
      "4d80f08808e648a78b6e80fd783ee599",
      "5693d199719e42dfb846aa5c48d81d1f",
      "b3474ce03a5248b5b0275e1804dbf2bf",
      "80840473181541789ad2d7e54cd65ef6",
      "6e4b2aca73de4081839adf9d9f0e999e",
      "a2a2871ddec14330a6185627e13b564a",
      "593375be0e514f2f9028ad117f88c4ff",
      "057cf6ed0f7a4dc190b91cc6c6fcb54c",
      "79dddee22f814490bda2f7a43b161c08",
      "e136d760f9bc4e2c939631bf01edfb97",
      "181196bf158c43c8afdea0384a5d7155",
      "e153f42afaa64d47833bd847ce3db7e2",
      "0e8ff5019f0c49db8b7d1d8829153649",
      "b75ba8671a3f437db7c5c30fd9fac8aa",
      "7fb0a5f3937042678b38071e61a5cbe9",
      "f0b4eca7a76f449e805d2a8ac51c76fe",
      "f731352d0aa24110b2bf924dc9448829",
      "bd4e4bf03b2746249abf0a413a3b67aa",
      "d9e96d1f12ce450cad31a160e1b04ad0",
      "1a8e23ae36ba438ca5921d9a80054da8",
      "2c4b02b4695a44cb901ac15aed1da3ee",
      "ed9c8f9e725f437090f325c1e9897ace",
      "d8b276e4aa7545b59315631ea6be4237",
      "ded962f4285f437bae68a108b7621636",
      "70b566a009e746eb812cd71eadc71253"
     ]
    },
    "id": "x6lyU9itq-fa",
    "outputId": "7c87bada-4fed-462c-f0c7-59ac09cfc56b"
   },
   "outputs": [],
   "source": [
    "output_dir = \"tinyllama_disease_qlora\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=2e-4,\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    weight_decay=0.01,\n",
    "    bf16=torch.cuda.is_available(),\n",
    "    report_to=\"none\"\n",
    ")\n",
    "dataset_small = datset.select(range(200))\n",
    "dataset_test_small = datset_test.select(range(100))\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset_small,\n",
    "    eval_dataset=dataset_test_small,\n",
    "    peft_config=lora_config,\n",
    "    args=training_args,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6XB23ilUkCIC",
    "outputId": "287ba60f-3f41-41e4-ce9a-cecef1336a16"
   },
   "outputs": [],
   "source": [
    "save_dir = \"tinyllama_disease_qlora_adapter\"\n",
    "trainer.model.save_pretrained(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "print(\"Saved adapter to:\", save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pMfmmKYrkKTT",
    "outputId": "b743d147-6365-4a80-b31c-6031f7818df9"
   },
   "outputs": [],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "inference_model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    save_dir,\n",
    "    device_map=\"auto\",)\n",
    "inference_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dzJMov8TkmQC",
    "outputId": "03954f41-f26c-4608-df8a-dab892b084d8"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def build_prompt(example):\n",
    "    return (\n",
    "        f\"Instruction: {example['instruction']}\\n\"\n",
    "        f\"Symptoms: {example['input']}\\n\\n\"\n",
    "        \"Response:\\n\"\n",
    "    )\n",
    "\n",
    "def extract_disease_from_output(text):\n",
    "    \"\"\"\n",
    "    Try to extract the disease name from lines like:\n",
    "    'Disease: dengue'\n",
    "    'Possible condition: Dengue-like pattern (from dataset)'\n",
    "    \"\"\"\n",
    "    m = re.search(r\"Disease:\\s*([^\\n\\r]+)\", text, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        return m.group(1).strip()\n",
    "\n",
    "    m2 = re.search(r\"Possible\\s+condition:\\s*([^\\n\\r]+)\", text, flags=re.IGNORECASE)\n",
    "    if m2:\n",
    "        return m2.group(1).strip()\n",
    "\n",
    "    return \"Unknown\"\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for ex in tqdm(raw_datasets[\"test\"]):\n",
    "    prompt = build_prompt(ex)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(inference_model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = inference_model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=128,\n",
    "            do_sample=False,\n",
    "            temperature=0.0\n",
    "        )\n",
    "\n",
    "    decoded = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    if \"Response:\" in decoded:\n",
    "        generated_part = decoded.split(\"Response:\", 1)[1]\n",
    "    else:\n",
    "        generated_part = decoded\n",
    "\n",
    "    pred_disease = extract_disease_from_output(generated_part)\n",
    "    y_pred.append(pred_disease)\n",
    "    y_true.append(ex[\"label\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQv6ZmDqwxye"
   },
   "source": [
    "EVALUATION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yJDWiyDkw0mc",
    "outputId": "05eb138e-5226-4797-9a31-fec92ea2a6fb"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "counter = Counter(y_true)\n",
    "top_20_diseases = [d for d, _ in counter.most_common(20)]\n",
    "\n",
    "# Filter to those\n",
    "filtered_true = []\n",
    "filtered_pred = []\n",
    "for t, p in zip(y_true, y_pred):\n",
    "    if t in top_20_diseases:\n",
    "        filtered_true.append(t)\n",
    "        filtered_pred.append(p if p in top_20_diseases else \"Other/Unknown\")\n",
    "\n",
    "labels = top_20_diseases + [\"Other/Unknown\"]\n",
    "\n",
    "cm = confusion_matrix(filtered_true, filtered_pred, labels=labels)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "im = ax.imshow(cm, interpolation=\"nearest\")\n",
    "ax.set_title(\"Confusion Matrix â€“ Disease (Top 20) vs Predicted Disease\")\n",
    "plt.colorbar(im, ax=ax)\n",
    "\n",
    "tick_marks = np.arange(len(labels))\n",
    "ax.set_xticks(tick_marks)\n",
    "ax.set_xticklabels(labels, rotation=90)\n",
    "ax.set_yticks(tick_marks)\n",
    "ax.set_yticklabels(labels)\n",
    "\n",
    "ax.set_ylabel(\"Actual Disease\")\n",
    "ax.set_xlabel(\"Predicted Disease\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix_top20.png\", dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xHrSeOTxNAp"
   },
   "source": [
    "DEMO QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ddQa6qukzDRp",
    "outputId": "066b5f4b-fd13-4a34-f200-027e9196754c"
   },
   "outputs": [],
   "source": [
    "def query_model(symptoms_text: str):\n",
    "    instruction = \"Identify the most likely disease pattern from the dataset based on these symptoms.\"\n",
    "    prompt = (\n",
    "        f\"Instruction: {instruction}\\n\"\n",
    "        f\"Symptoms: {symptoms_text}\\n\\n\"\n",
    "        \"Response:\\n\"\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(inference_model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = inference_model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=128,\n",
    "            do_sample=False,\n",
    "            temperature=0.0\n",
    "        )\n",
    "\n",
    "    decoded = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    if \"Response:\" in decoded:\n",
    "        decoded = decoded.split(\"Response:\", 1)[1].strip()\n",
    "\n",
    "    return decoded\n",
    "test_cases = [\n",
    "    \"Fever, headache, body pain\",#test case1\n",
    "    \"Cough, sore throat, runny nose\",#test case2\n",
    "    \"Abdominal pain, vomiting, diarrhea\"#test case3\n",
    "]\n",
    "print(\"MODEL RESPONSES FOR 3 TEST CASES ARE:\")\n",
    "for i, symptoms in enumerate(test_cases, start=1):\n",
    "    print(f\"------ Test Case {i} ------\")\n",
    "    print(\"Symptoms:\", symptoms)\n",
    "    print(\"\\nModel Output:\\n\")\n",
    "    print(query_model(symptoms))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
